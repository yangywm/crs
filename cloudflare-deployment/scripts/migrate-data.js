#!/usr/bin/env node

/**
 * æ•°æ®è¿ç§»è„šæœ¬
 * ä»ä¼ ç»ŸRediséƒ¨ç½²è¿ç§»åˆ°Cloudflare D1
 */

const fs = require('fs')
const path = require('path')
const Redis = require('ioredis')

class DataMigrator {
  constructor(options = {}) {
    this.redisConfig = options.redis || {
      host: 'localhost',
      port: 6379,
      password: '',
      db: 0
    }
    
    this.outputDir = options.outputDir || './migration-data'
    this.redis = null
  }

  async connect() {
    console.log('ğŸ”— è¿æ¥åˆ°Redis...')
    this.redis = new Redis(this.redisConfig)
    
    try {
      await this.redis.ping()
      console.log('âœ… Redisè¿æ¥æˆåŠŸ')
    } catch (error) {
      console.error('âŒ Redisè¿æ¥å¤±è´¥:', error.message)
      throw error
    }
  }

  async disconnect() {
    if (this.redis) {
      await this.redis.disconnect()
      console.log('ğŸ”Œ Redisè¿æ¥å·²æ–­å¼€')
    }
  }

  async exportData() {
    console.log('ğŸ“¤ å¼€å§‹å¯¼å‡ºæ•°æ®...')
    
    // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if (!fs.existsSync(this.outputDir)) {
      fs.mkdirSync(this.outputDir, { recursive: true })
    }

    const data = {
      users: await this.exportUsers(),
      claudeAccounts: await this.exportClaudeAccounts(),
      apiKeys: await this.exportApiKeys(),
      usageStats: await this.exportUsageStats(),
      settings: await this.exportSettings(),
      exportTime: new Date().toISOString()
    }

    // ä¿å­˜åˆ°æ–‡ä»¶
    const exportFile = path.join(this.outputDir, 'crs-export.json')
    fs.writeFileSync(exportFile, JSON.stringify(data, null, 2))
    
    console.log(`âœ… æ•°æ®å¯¼å‡ºå®Œæˆ: ${exportFile}`)
    return data
  }

  async exportUsers() {
    console.log('ğŸ‘¥ å¯¼å‡ºç”¨æˆ·æ•°æ®...')
    const users = []
    
    try {
      const userKeys = await this.redis.keys('user:*')
      
      for (const key of userKeys) {
        const userData = await this.redis.hgetall(key)
        if (userData && userData.username) {
          users.push({
            id: userData.id || key.replace('user:', ''),
            username: userData.username,
            password: userData.password,
            email: userData.email,
            role: userData.role || 'user',
            status: userData.status || 'active',
            created_at: userData.created_at || new Date().toISOString(),
            updated_at: userData.updated_at || new Date().toISOString()
          })
        }
      }
      
      console.log(`  å¯¼å‡º ${users.length} ä¸ªç”¨æˆ·`)
    } catch (error) {
      console.warn('âš ï¸  ç”¨æˆ·æ•°æ®å¯¼å‡ºå¤±è´¥:', error.message)
    }
    
    return users
  }

  async exportClaudeAccounts() {
    console.log('ğŸ¤– å¯¼å‡ºClaudeè´¦æˆ·æ•°æ®...')
    const accounts = []
    
    try {
      const accountKeys = await this.redis.keys('claude_account:*')
      
      for (const key of accountKeys) {
        const accountData = await this.redis.hgetall(key)
        if (accountData && accountData.name) {
          accounts.push({
            id: accountData.id || key.replace('claude_account:', ''),
            name: accountData.name,
            authorization: accountData.authorization,
            proxy_config: accountData.proxy_config ? JSON.parse(accountData.proxy_config) : null,
            group_id: accountData.group_id,
            status: accountData.status || 'active',
            last_used_at: accountData.last_used_at,
            error_count: parseInt(accountData.error_count) || 0,
            created_at: accountData.created_at || new Date().toISOString(),
            updated_at: accountData.updated_at || new Date().toISOString()
          })
        }
      }
      
      console.log(`  å¯¼å‡º ${accounts.length} ä¸ªClaudeè´¦æˆ·`)
    } catch (error) {
      console.warn('âš ï¸  Claudeè´¦æˆ·æ•°æ®å¯¼å‡ºå¤±è´¥:', error.message)
    }
    
    return accounts
  }

  async exportApiKeys() {
    console.log('ğŸ”‘ å¯¼å‡ºAPI Keyæ•°æ®...')
    const apiKeys = []
    
    try {
      const keyKeys = await this.redis.keys('api_key:*')
      
      for (const key of keyKeys) {
        const keyData = await this.redis.hgetall(key)
        if (keyData && keyData.name) {
          apiKeys.push({
            id: keyData.id || key.replace('api_key:', ''),
            name: keyData.name,
            key_hash: keyData.key_hash,
            user_id: keyData.user_id,
            limits: keyData.limits ? JSON.parse(keyData.limits) : null,
            client_restrictions: keyData.client_restrictions ? JSON.parse(keyData.client_restrictions) : null,
            status: keyData.status || 'active',
            expires_at: keyData.expires_at,
            last_used_at: keyData.last_used_at,
            usage_count: parseInt(keyData.usage_count) || 0,
            created_at: keyData.created_at || new Date().toISOString(),
            updated_at: keyData.updated_at || new Date().toISOString()
          })
        }
      }
      
      console.log(`  å¯¼å‡º ${apiKeys.length} ä¸ªAPI Key`)
    } catch (error) {
      console.warn('âš ï¸  API Keyæ•°æ®å¯¼å‡ºå¤±è´¥:', error.message)
    }
    
    return apiKeys
  }

  async exportUsageStats() {
    console.log('ğŸ“Š å¯¼å‡ºä½¿ç”¨ç»Ÿè®¡æ•°æ®...')
    const usageStats = []
    
    try {
      const statsKeys = await this.redis.keys('usage_stat:*')
      
      for (const key of statsKeys) {
        const statData = await this.redis.hgetall(key)
        if (statData && statData.api_key_id) {
          usageStats.push({
            id: statData.id || key.replace('usage_stat:', ''),
            api_key_id: statData.api_key_id,
            account_id: statData.account_id,
            account_type: statData.account_type || 'claude',
            model: statData.model,
            input_tokens: parseInt(statData.input_tokens) || 0,
            output_tokens: parseInt(statData.output_tokens) || 0,
            cost: parseFloat(statData.cost) || 0,
            request_id: statData.request_id,
            user_agent: statData.user_agent,
            ip_address: statData.ip_address,
            timestamp: statData.timestamp || new Date().toISOString()
          })
        }
      }
      
      console.log(`  å¯¼å‡º ${usageStats.length} æ¡ä½¿ç”¨ç»Ÿè®¡`)
    } catch (error) {
      console.warn('âš ï¸  ä½¿ç”¨ç»Ÿè®¡æ•°æ®å¯¼å‡ºå¤±è´¥:', error.message)
    }
    
    return usageStats
  }

  async exportSettings() {
    console.log('âš™ï¸  å¯¼å‡ºç³»ç»Ÿè®¾ç½®...')
    const settings = {}
    
    try {
      const settingKeys = await this.redis.keys('setting:*')
      
      for (const key of settingKeys) {
        const settingValue = await this.redis.get(key)
        if (settingValue) {
          const settingKey = key.replace('setting:', '')
          try {
            settings[settingKey] = JSON.parse(settingValue)
          } catch {
            settings[settingKey] = settingValue
          }
        }
      }
      
      console.log(`  å¯¼å‡º ${Object.keys(settings).length} ä¸ªè®¾ç½®é¡¹`)
    } catch (error) {
      console.warn('âš ï¸  ç³»ç»Ÿè®¾ç½®å¯¼å‡ºå¤±è´¥:', error.message)
    }
    
    return settings
  }

  generateD1ImportSQL(data) {
    console.log('ğŸ”„ ç”ŸæˆD1å¯¼å…¥SQL...')
    
    const sql = []
    
    // å¯¼å…¥ç”¨æˆ·
    if (data.users && data.users.length > 0) {
      sql.push('-- å¯¼å…¥ç”¨æˆ·æ•°æ®')
      for (const user of data.users) {
        sql.push(`INSERT OR REPLACE INTO users (id, username, password, email, role, status, created_at, updated_at) VALUES (
          '${user.id}',
          '${user.username}',
          '${user.password}',
          '${user.email || ''}',
          '${user.role}',
          '${user.status}',
          '${user.created_at}',
          '${user.updated_at}'
        );`)
      }
      sql.push('')
    }

    // å¯¼å…¥Claudeè´¦æˆ·
    if (data.claudeAccounts && data.claudeAccounts.length > 0) {
      sql.push('-- å¯¼å…¥Claudeè´¦æˆ·æ•°æ®')
      for (const account of data.claudeAccounts) {
        sql.push(`INSERT OR REPLACE INTO claude_accounts (id, name, authorization, proxy_config, group_id, status, last_used_at, error_count, created_at, updated_at) VALUES (
          '${account.id}',
          '${account.name}',
          '${account.authorization}',
          '${account.proxy_config ? JSON.stringify(account.proxy_config).replace(/'/g, "''") : ''}',
          '${account.group_id || ''}',
          '${account.status}',
          '${account.last_used_at || ''}',
          ${account.error_count},
          '${account.created_at}',
          '${account.updated_at}'
        );`)
      }
      sql.push('')
    }

    // å¯¼å…¥API Keys
    if (data.apiKeys && data.apiKeys.length > 0) {
      sql.push('-- å¯¼å…¥API Keyæ•°æ®')
      for (const apiKey of data.apiKeys) {
        sql.push(`INSERT OR REPLACE INTO api_keys (id, name, key_hash, user_id, limits, client_restrictions, status, expires_at, last_used_at, usage_count, created_at, updated_at) VALUES (
          '${apiKey.id}',
          '${apiKey.name}',
          '${apiKey.key_hash}',
          '${apiKey.user_id || ''}',
          '${apiKey.limits ? JSON.stringify(apiKey.limits).replace(/'/g, "''") : ''}',
          '${apiKey.client_restrictions ? JSON.stringify(apiKey.client_restrictions).replace(/'/g, "''") : ''}',
          '${apiKey.status}',
          '${apiKey.expires_at || ''}',
          '${apiKey.last_used_at || ''}',
          ${apiKey.usage_count},
          '${apiKey.created_at}',
          '${apiKey.updated_at}'
        );`)
      }
      sql.push('')
    }

    // å¯¼å…¥ç³»ç»Ÿè®¾ç½®
    if (data.settings && Object.keys(data.settings).length > 0) {
      sql.push('-- å¯¼å…¥ç³»ç»Ÿè®¾ç½®')
      for (const [key, value] of Object.entries(data.settings)) {
        sql.push(`INSERT OR REPLACE INTO settings (key, value, updated_at) VALUES (
          '${key}',
          '${JSON.stringify(value).replace(/'/g, "''")}',
          '${new Date().toISOString()}'
        );`)
      }
    }

    const sqlContent = sql.join('\n')
    const sqlFile = path.join(this.outputDir, 'import.sql')
    fs.writeFileSync(sqlFile, sqlContent)
    
    console.log(`âœ… SQLå¯¼å…¥æ–‡ä»¶ç”Ÿæˆå®Œæˆ: ${sqlFile}`)
    return sqlFile
  }
}

// å‘½ä»¤è¡Œæ¥å£
async function main() {
  const args = process.argv.slice(2)
  
  if (args.includes('--help') || args.includes('-h')) {
    console.log(`
CRSæ•°æ®è¿ç§»å·¥å…·

ç”¨æ³•:
  node migrate-data.js [é€‰é¡¹]

é€‰é¡¹:
  --redis-host HOST     Redisä¸»æœºåœ°å€ (é»˜è®¤: localhost)
  --redis-port PORT     Redisç«¯å£ (é»˜è®¤: 6379)
  --redis-password PWD  Rediså¯†ç 
  --redis-db DB         Redisæ•°æ®åº“ç¼–å· (é»˜è®¤: 0)
  --output-dir DIR      è¾“å‡ºç›®å½• (é»˜è®¤: ./migration-data)
  --help, -h            æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  node migrate-data.js --redis-host 127.0.0.1 --redis-port 6379
  node migrate-data.js --output-dir /tmp/crs-migration
`)
    return
  }

  // è§£æå‘½ä»¤è¡Œå‚æ•°
  const config = {
    redis: {
      host: 'localhost',
      port: 6379,
      password: '',
      db: 0
    },
    outputDir: './migration-data'
  }

  for (let i = 0; i < args.length; i += 2) {
    const arg = args[i]
    const value = args[i + 1]
    
    switch (arg) {
      case '--redis-host':
        config.redis.host = value
        break
      case '--redis-port':
        config.redis.port = parseInt(value)
        break
      case '--redis-password':
        config.redis.password = value
        break
      case '--redis-db':
        config.redis.db = parseInt(value)
        break
      case '--output-dir':
        config.outputDir = value
        break
    }
  }

  const migrator = new DataMigrator(config)

  try {
    await migrator.connect()
    const data = await migrator.exportData()
    migrator.generateD1ImportSQL(data)
    
    console.log('\nğŸ‰ æ•°æ®è¿ç§»å‡†å¤‡å®Œæˆï¼')
    console.log('\nä¸‹ä¸€æ­¥æ“ä½œ:')
    console.log('1. æ£€æŸ¥å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶')
    console.log('2. ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯¼å…¥åˆ°D1æ•°æ®åº“:')
    console.log(`   wrangler d1 execute crs-database --file=${path.join(config.outputDir, 'import.sql')}`)
    
  } catch (error) {
    console.error('âŒ è¿ç§»å¤±è´¥:', error.message)
    process.exit(1)
  } finally {
    await migrator.disconnect()
  }
}

if (require.main === module) {
  main().catch(console.error)
}

module.exports = { DataMigrator }